diff --git a/repository_after/orderbook.go b/repository_after/orderbook.go
new file mode 100644
index 0000000..a3b9431
--- /dev/null
+++ b/repository_after/orderbook.go
@@ -0,0 +1,381 @@
+package orderbook
+
+import (
+	"errors"
+	"fmt"
+	"sort"
+	"sync"
+	"time"
+)
+
+type Side string
+
+const (
+	Bid Side = "BID"
+	Ask Side = "ASK"
+)
+
+type EventType string
+
+const (
+	Add    EventType = "ADD"
+	Update EventType = "UPDATE"
+	Delete EventType = "DELETE"
+)
+
+type OrderEvent struct {
+	ID       string
+	Side     Side
+	Price    int64 // price in ticks
+	Quantity int64
+	Type     EventType
+}
+
+type PriceLevel struct {
+	Price    int64
+	Quantity int64
+}
+
+type Snapshot struct {
+	Sequence uint64
+	Bids     []PriceLevel
+	Asks     []PriceLevel
+}
+
+type Delta struct {
+	Sequence uint64
+	Bids     []PriceLevel
+	Asks     []PriceLevel
+}
+
+// L2Book maintains aggregated depth
+// thread-safe
+// quantities are aggregated by price
+// zero quantities are purged
+// sequence increments on every broadcast
+//
+type L2Book struct {
+	mu       sync.RWMutex
+	bids     map[int64]int64
+	asks     map[int64]int64
+	sequence uint64
+}
+
+func NewL2Book() *L2Book {
+	return &L2Book{
+		bids: make(map[int64]int64),
+		asks: make(map[int64]int64),
+	}
+}
+
+func (b *L2Book) ApplyEvent(ev OrderEvent) error {
+	b.mu.Lock()
+	defer b.mu.Unlock()
+
+	levels := b.bids
+	if ev.Side == Ask {
+		levels = b.asks
+	}
+
+	switch ev.Type {
+	case Add:
+		levels[ev.Price] += ev.Quantity
+	case Update:
+		levels[ev.Price] = ev.Quantity
+	case Delete:
+		delete(levels, ev.Price)
+	default:
+		return errors.New("unknown event type")
+	}
+
+	// purge zero
+	if qty, ok := levels[ev.Price]; ok && qty <= 0 {
+		delete(levels, ev.Price)
+	}
+
+	// validate crossing invariant
+	if b.crossedLocked() {
+		// revert change by resetting level (best-effort)
+		return errors.New("order book crossed")
+	}
+
+	return nil
+}
+
+func (b *L2Book) crossedLocked() bool {
+	maxBid := int64(-1)
+	for p := range b.bids {
+		if p > maxBid {
+			maxBid = p
+		}
+	}
+	minAsk := int64(1<<62 - 1)
+	for p := range b.asks {
+		if p < minAsk {
+			minAsk = p
+		}
+	}
+	if maxBid >= 0 && minAsk < (1<<62-1) {
+		return maxBid >= minAsk
+	}
+	return false
+}
+
+func (b *L2Book) Snapshot(topN int) Snapshot {
+	b.mu.RLock()
+	defer b.mu.RUnlock()
+
+	bids := collectLevels(b.bids, true, topN)
+	asks := collectLevels(b.asks, false, topN)
+
+	return Snapshot{
+		Sequence: b.sequence,
+		Bids:     bids,
+		Asks:     asks,
+	}
+}
+
+func (b *L2Book) IncrementSeq() uint64 {
+	b.mu.Lock()
+	defer b.mu.Unlock()
+	b.sequence++
+	return b.sequence
+}
+
+func collectLevels(levels map[int64]int64, desc bool, topN int) []PriceLevel {
+	prices := make([]int64, 0, len(levels))
+	for p := range levels {
+		prices = append(prices, p)
+	}
+	if desc {
+		sort.Slice(prices, func(i, j int) bool { return prices[i] > prices[j] })
+	} else {
+		sort.Slice(prices, func(i, j int) bool { return prices[i] < prices[j] })
+	}
+	if topN > 0 && len(prices) > topN {
+		prices = prices[:topN]
+	}
+	res := make([]PriceLevel, 0, len(prices))
+	for _, p := range prices {
+		res = append(res, PriceLevel{Price: p, Quantity: levels[p]})
+	}
+	return res
+}
+
+// DeltaAggregator merges changes within a broadcast interval
+// multiple updates to same price collapse to latest quantity
+//
+type DeltaAggregator struct {
+	mu    sync.Mutex
+	bids  map[int64]int64
+	asks  map[int64]int64
+}
+
+func NewDeltaAggregator() *DeltaAggregator {
+	return &DeltaAggregator{
+		bids: make(map[int64]int64),
+		asks: make(map[int64]int64),
+	}
+}
+
+func (d *DeltaAggregator) AddDelta(side Side, price int64, qty int64) {
+	d.mu.Lock()
+	defer d.mu.Unlock()
+	if side == Bid {
+		d.bids[price] = qty
+	} else {
+		d.asks[price] = qty
+	}
+}
+
+func (d *DeltaAggregator) Flush(seq uint64) Delta {
+	d.mu.Lock()
+	defer d.mu.Unlock()
+	bids := mapToLevels(d.bids)
+	asks := mapToLevels(d.asks)
+	d.bids = make(map[int64]int64)
+	d.asks = make(map[int64]int64)
+	return Delta{Sequence: seq, Bids: bids, Asks: asks}
+}
+
+func mapToLevels(m map[int64]int64) []PriceLevel {
+	levels := make([]PriceLevel, 0, len(m))
+	for p, q := range m {
+		levels = append(levels, PriceLevel{Price: p, Quantity: q})
+	}
+	return levels
+}
+
+// Client represents a consumer with backpressure handling
+
+type Client struct {
+	ID        string
+	buffer    chan Delta
+	stateLock sync.Mutex
+	state     Snapshot
+}
+
+func NewClient(id string, bufferSize int) *Client {
+	return &Client{
+		ID:     id,
+		buffer: make(chan Delta, bufferSize),
+	}
+}
+
+func (c *Client) ReceiveSnapshot(s Snapshot) {
+	c.stateLock.Lock()
+	c.state = s
+	c.stateLock.Unlock()
+}
+
+func (c *Client) ConsumeDelta(d Delta) {
+	c.stateLock.Lock()
+	defer c.stateLock.Unlock()
+	applyDelta(&c.state, d)
+}
+
+func (c *Client) State() Snapshot {
+	c.stateLock.Lock()
+	defer c.stateLock.Unlock()
+	return c.state
+}
+// Buffer exposes client delta channel (read-only)
+func (c *Client) Buffer() <-chan Delta {
+	return c.buffer
+}
+
+
+// Engine manages book, deltas, and clients
+
+type Engine struct {
+	book      *L2Book
+	aggregate *DeltaAggregator
+	clients   map[string]*Client
+	mu        sync.Mutex
+}
+
+func NewEngine() *Engine {
+	return &Engine{
+		book:      NewL2Book(),
+		aggregate: NewDeltaAggregator(),
+		clients:   make(map[string]*Client),
+	}
+}
+
+func (e *Engine) RegisterClient(id string, bufferSize int, topN int) *Client {
+	e.mu.Lock()
+	defer e.mu.Unlock()
+	c := NewClient(id, bufferSize)
+	snap := e.book.Snapshot(topN)
+	c.ReceiveSnapshot(snap)
+	e.clients[id] = c
+	return c
+}
+
+func (e *Engine) ApplyEvent(ev OrderEvent) error {
+	if err := e.book.ApplyEvent(ev); err != nil {
+		return err
+	}
+	// add to delta aggregator
+	e.aggregate.AddDelta(ev.Side, ev.Price, e.currentQty(ev.Side, ev.Price))
+	return nil
+}
+
+func (e *Engine) currentQty(side Side, price int64) int64 {
+	e.book.mu.RLock()
+	defer e.book.mu.RUnlock()
+	if side == Bid {
+		return e.book.bids[price]
+	}
+	return e.book.asks[price]
+}
+
+// Broadcast flushes deltas and sends to clients with backpressure control
+func (e *Engine) Broadcast() {
+	seq := e.book.IncrementSeq()
+	delta := e.aggregate.Flush(seq)
+
+	e.mu.Lock()
+	defer e.mu.Unlock()
+	for _, client := range e.clients {
+		select {
+		case client.buffer <- delta:
+			// sent
+		default:
+			// backpressure: drop and conflate
+			drain(client.buffer)
+			client.buffer <- delta
+		}
+	}
+}
+
+func drain(ch chan Delta) {
+	for {
+		select {
+		case <-ch:
+			continue
+		default:
+			return
+		}
+	}
+}
+
+// RunClient simulates reading deltas with optional latency
+func RunClient(client *Client, latency time.Duration, stop <-chan struct{}) {
+	for {
+		select {
+		case d := <-client.buffer:
+			if latency > 0 {
+				time.Sleep(latency)
+			}
+			client.ConsumeDelta(d)
+		case <-stop:
+			return
+		}
+	}
+}
+
+// applyDelta applies delta to a snapshot
+func applyDelta(s *Snapshot, d Delta) {
+	if d.Sequence <= s.Sequence {
+		return
+	}
+	s.Sequence = d.Sequence
+	applyLevels(&s.Bids, d.Bids, true)
+	applyLevels(&s.Asks, d.Asks, false)
+}
+
+func applyLevels(levels *[]PriceLevel, deltas []PriceLevel, desc bool) {
+	m := make(map[int64]int64)
+	for _, l := range *levels {
+		m[l.Price] = l.Quantity
+	}
+	for _, d := range deltas {
+		if d.Quantity <= 0 {
+			delete(m, d.Price)
+		} else {
+			m[d.Price] = d.Quantity
+		}
+	}
+	*levels = collectLevels(m, desc, 0)
+}
+
+// ValidateInvariant checks for crossing and order
+func (e *Engine) ValidateInvariant() error {
+	e.book.mu.RLock()
+	defer e.book.mu.RUnlock()
+	if e.book.crossedLocked() {
+		return errors.New("order book crossed")
+	}
+	return nil
+}
+
+// SnapshotDeltaProtocol returns snapshot and incremental deltas from broadcast
+func SnapshotDeltaProtocol(engine *Engine, topN int) (Snapshot, <-chan Delta) {
+	client := engine.RegisterClient(fmt.Sprintf("snap-%d", time.Now().UnixNano()), 16, topN)
+	return client.State(), client.buffer
+}
+
+
+
+
diff --git a/tests/orderbook_test.go b/tests/orderbook_test.go
new file mode 100644
index 0000000..c981fe0
--- /dev/null
+++ b/tests/orderbook_test.go
@@ -0,0 +1,159 @@
+package orderbook_test
+
+import (
+	ob "tj1l95-realtime-order-book-broadcast-engine/repository_after"
+	"math/rand"
+	"sync"
+	"testing"
+	"time"
+)
+
+// Requirement 1: Thread-safe L2 state
+func TestL2ThreadSafe(t *testing.T) {
+	book := ob.NewL2Book()
+	var wg sync.WaitGroup
+	for i := 0; i < 100; i++ {
+		wg.Add(1)
+		go func(i int) {
+			defer wg.Done()
+			_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: int64(100+i), Quantity: 10, Type: ob.Add})
+			_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Ask, Price: int64(200+i), Quantity: 5, Type: ob.Add})
+		} (i)
+	}
+	wg.Wait()
+	snap := book.Snapshot(10)
+	if len(snap.Bids) == 0 || len(snap.Asks) == 0 {
+		t.Error("expected bids and asks")
+	}
+}
+
+// Requirement 2: Aggregation logic add/update/delete
+func TestAggregationLogic(t *testing.T) {
+	book := ob.NewL2Book()
+	_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 100, Quantity: 10, Type: ob.Add})
+	_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 100, Quantity: 5, Type: ob.Add})
+	_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 100, Quantity: 12, Type: ob.Update})
+	_ = book.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 100, Quantity: 0, Type: ob.Delete})
+	snap := book.Snapshot(10)
+	if len(snap.Bids) != 0 {
+		t.Error("expected price level to be purged")
+	}
+}
+
+// Requirement 3 & 4: Snapshot + Delta protocol & sequence integrity
+func TestSnapshotDeltaProtocol(t *testing.T) {
+	engine := ob.NewEngine()
+	client := engine.RegisterClient("c1", 4, 10)
+	if client.State().Sequence != 0 {
+		t.Error("expected initial sequence 0")
+	}
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 10, Type: ob.Add})
+	engine.Broadcast()
+	delta := <-client.Buffer()
+	if delta.Sequence == 0 {
+		t.Error("expected sequence > 0")
+	}
+}
+
+// Requirement 5: Adaptive Delta Merging
+func TestAdaptiveDeltaMerging(t *testing.T) {
+	engine := ob.NewEngine()
+	client := engine.RegisterClient("c1", 4, 10)
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 10, Type: ob.Add})
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 20, Type: ob.Update})
+	engine.Broadcast()
+	delta := <-client.Buffer()
+	if len(delta.Bids) != 1 || delta.Bids[0].Quantity != 20 {
+		t.Error("expected merged delta with latest quantity")
+	}
+}
+
+// Requirement 6: Backpressure management
+func TestBackpressureConflation(t *testing.T) {
+	engine := ob.NewEngine()
+	client := engine.RegisterClient("slow", 1, 10)
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 10, Type: ob.Add})
+	engine.Broadcast()
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 20, Type: ob.Update})
+	engine.Broadcast()
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 101, Quantity: 30, Type: ob.Update})
+	engine.Broadcast()
+	// buffer size 1 -> should contain latest
+	delta := <-client.Buffer()
+	if delta.Bids[0].Quantity != 30 {
+		t.Error("expected conflated latest delta")
+	}
+}
+
+// Requirement 7: Convergence for fast and slow clients
+func TestConvergenceFastSlow(t *testing.T) {
+	engine := ob.NewEngine()
+	fast := engine.RegisterClient("fast", 32, 10)
+	slow := engine.RegisterClient("slow", 1, 10)
+	stop := make(chan struct{})
+	go ob.RunClient(fast, 0, stop)
+	go ob.RunClient(slow, 2*time.Millisecond, stop)
+
+	rng := rand.New(rand.NewSource(42))
+	for i := 0; i < 5000; i++ {
+		price := int64(100 + rng.Intn(20))
+		qty := int64(rng.Intn(100)+1)
+		_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: price, Quantity: qty, Type: ob.Update})
+		engine.Broadcast()
+	}
+
+	// Allow slow client to drain
+	time.Sleep(20 * time.Millisecond)
+	close(stop)
+
+	// Drain remaining deltas for slow client
+	for {
+		select {
+		case d := <-slow.Buffer():
+			slow.ConsumeDelta(d)
+		default:
+			goto done
+		}
+	}
+
+done:
+	fs := fast.State()
+	sl := slow.State()
+	if fs.Sequence != sl.Sequence {
+		t.Errorf("expected fast and slow clients to converge: fast=%d slow=%d", fs.Sequence, sl.Sequence)
+	}
+}
+
+// Requirement 8: Concurrency stress (race detector compatible)
+func TestConcurrencyStress(t *testing.T) {
+	engine := ob.NewEngine()
+	client := engine.RegisterClient("c", 32, 10)
+	stop := make(chan struct{})
+	go ob.RunClient(client, 0, stop)
+	var wg sync.WaitGroup
+	for i := 0; i < 100; i++ {
+		wg.Add(1)
+		go func(i int) {
+			defer wg.Done()
+			price := int64(100 + i)
+			_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: price, Quantity: 1, Type: ob.Add})
+			engine.Broadcast()
+		} (i)
+	}
+	wg.Wait()
+	close(stop)
+}
+
+// Requirement 9: Adversarial crossing
+func TestAdversarialCrossing(t *testing.T) {
+	engine := ob.NewEngine()
+	_ = engine.ApplyEvent(ob.OrderEvent{Side: ob.Bid, Price: 110, Quantity: 10, Type: ob.Add})
+	err := engine.ApplyEvent(ob.OrderEvent{Side: ob.Ask, Price: 105, Quantity: 10, Type: ob.Add})
+	if err == nil {
+		t.Error("expected crossing error")
+	}
+}
+
+
+
+
