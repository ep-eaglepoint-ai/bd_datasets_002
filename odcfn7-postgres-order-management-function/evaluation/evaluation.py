"""
Evaluation runner for PostgreSQL Order Management Function.
Runs tests against repository_after and generates structured reports.
"""
import subprocess
import sys
import os
import json
import uuid
import platform
import xml.etree.ElementTree as ET
from datetime import datetime, timezone

# Configuration
TASK_TITLE = "PostgreSQL Order Management Function"
TEST_DIR = "/app/tests"
REPORT_XML_PATH = "/tmp/test-report.xml"
REPORTS_BASE_DIR = "/app/evaluation/reports"

def get_environment_info():
    """Gather environment metadata."""
    return {
        "python_version": platform.python_version(),
        "platform": platform.platform(),
        "os": platform.system(),
        "git_commit": "unknown", 
        "git_branch": "unknown"
    }

def run_tests_and_generate_xml():
    """Run pytest, capture stdout, and generate JUnit XML for parsing."""
    # We use --junitxml to get structured data for the report
    # -v ensures verbose stdout is captured for the log
    cmd = ["pytest", TEST_DIR, "-v", f"--junitxml={REPORT_XML_PATH}"]
    
    start_time = datetime.now(timezone.utc)
    
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        cwd="/app"
    )
    
    end_time = datetime.now(timezone.utc)
    duration = (end_time - start_time).total_seconds()
    
    return {
        "returncode": result.returncode,
        "stdout": result.stdout,
        "stderr": result.stderr,
        "start_time": start_time,
        "end_time": end_time,
        "duration": duration
    }

def parse_xml_results():
    """Parse the JUnit XML file generated by pytest."""
    if not os.path.exists(REPORT_XML_PATH):
        return [], {"total": 0, "passed": 0, "failed": 0, "errors": 0, "skipped": 0}

    tree = ET.parse(REPORT_XML_PATH)
    root = tree.getroot()
    
    tests = []
    summary = {"total": 0, "passed": 0, "failed": 0, "errors": 0, "skipped": 0}
    
    # Iterate over all testcases in the XML
    for case in root.iter("testcase"):
        summary["total"] += 1
        
        # Attributes from XML
        classname = case.get("classname")  # e.g., tests.test_main.TestSuccessfulOrderProcessing
        name = case.get("name")            # e.g., test_successful_order_creation
        file_path = case.get("file", "unknown_file")
        
        # Construct a nodeid similar to pytest (path::class::method)
        nodeid = f"{file_path}::{classname.split('.')[-1]}::{name}"

        # Determine status
        outcome = "passed"
        if case.find("failure") is not None:
            outcome = "failed"
            summary["failed"] += 1
        elif case.find("error") is not None:
            outcome = "failed" # Treat error as fail for simple reporting
            summary["errors"] += 1
        elif case.find("skipped") is not None:
            outcome = "skipped"
            summary["skipped"] += 1
        else:
            summary["passed"] += 1

        tests.append({
            "nodeid": nodeid,
            "name": name,
            "outcome": outcome
        })

    return tests, summary

def generate_criteria_analysis(tests):
    """
    Map passing tests to specific project requirements based on your specific Test Classes.
    """
    def check_pass(keyword):
        """Returns True if any passed test name contains the keyword."""
        return any(t["outcome"] == "passed" and keyword in t["name"] for t in tests)

    return {
        "happy_path_processing": "Checked via test_successful_order_creation" if check_pass("successful_order") else "Failed/Missing",
        "inventory_management": "Checked via test_inventory_is_deducted" if check_pass("inventory_is_deducted") else "Failed/Missing",
        "input_validation": "Checked via TestInputValidation (negative/null checks)" if check_pass("negative_quantity") or check_pass("null_customer") else "Failed/Missing",
        "idempotency_check": "Checked via test_duplicate_request_rejected" if check_pass("duplicate_request") else "Failed/Missing",
        "transactional_integrity": "Checked via test_failed_order_does_not_affect_inventory" if check_pass("failed_order_does_not_affect") else "Failed/Missing",
        "audit_logging": "Checked via test_audit_log_created_on_success" if check_pass("audit_log") else "Failed/Missing",
        "business_rules": "Checked via test_inactive_customer_rejected" if check_pass("inactive_customer") else "Failed/Missing"
    }

def save_report(report, reports_dir):
    """Save JSON report to file."""
    os.makedirs(reports_dir, exist_ok=True)
    report_path = os.path.join(reports_dir, "report.json")
    
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2)
    
    return report_path

def main():
    # 1. Setup
    run_id = str(uuid.uuid4())[:8]
    env_info = get_environment_info()
    
    print(f"Run ID: {run_id}")
    print(f"Tool: {TASK_TITLE}")
    print("=" * 60)
    print("RUNNING TESTS...")
    
    # 2. Execution
    execution_data = run_tests_and_generate_xml()
    
    # 3. Parsing
    test_details, summary = parse_xml_results()
    
    # 4. Analysis
    # Success is defined as return code 0 AND no failures/errors
    success = (execution_data["returncode"] == 0) and (summary["failed"] == 0) and (summary["errors"] == 0)
    
    criteria = generate_criteria_analysis(test_details)
    
    # 5. Construct Report
    report = {
        "run_id": run_id,
        "tool": TASK_TITLE,
        "started_at": execution_data["start_time"].isoformat(),
        "finished_at": execution_data["end_time"].isoformat(),
        "duration_seconds": round(execution_data["duration"], 4),
        "environment": env_info,
        "results": {
            "success": success,
            "exit_code": execution_data["returncode"],
            "tests": test_details,
            "summary": summary,
            "stdout": execution_data["stdout"],
            "stderr": execution_data["stderr"]
        },
        "criteria_analysis": criteria,
        "success": success,
        "error": None if success else "Tests failed or execution errors occurred"
    }

    # 6. Save
    date_str = execution_data["start_time"].strftime("%Y-%m-%d")
    time_str = execution_data["start_time"].strftime("%H-%M-%S")
    reports_dir = os.path.join(REPORTS_BASE_DIR, date_str, time_str)
    
    report_path = save_report(report, reports_dir)
    
    # 7. Output Summary to Console
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Outcome: {'SUCCESS' if success else 'FAILURE'}")
    print(f"Passed: {summary['passed']}/{summary['total']}")
    print(f"Duration: {report['duration_seconds']}s")
    print(f"Report saved: {report_path}")
    
    # Cleanup XML
    if os.path.exists(REPORT_XML_PATH):
        os.remove(REPORT_XML_PATH)

    # Exit with code 0 if success, 1 if failure
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()