diff --git a/repository_before/__pycache__/main.cpython-311.pyc b/repository_after/__pycache__/main.cpython-311.pyc
index 478793f..aeef76c 100644
Binary files a/repository_before/__pycache__/main.cpython-311.pyc and b/repository_after/__pycache__/main.cpython-311.pyc differ
diff --git a/repository_before/__pycache__/main.cpython-313.pyc b/repository_after/__pycache__/main.cpython-313.pyc
index 4a7e02d..a17e364 100644
Binary files a/repository_before/__pycache__/main.cpython-313.pyc and b/repository_after/__pycache__/main.cpython-313.pyc differ
diff --git a/repository_before/main.py b/repository_after/main.py
index 54d4b17..1104e59 100644
--- a/repository_before/main.py
+++ b/repository_after/main.py
@@ -1,190 +1,194 @@
 import time
 import threading
-import hashlib
 import json
 import copy
+import heapq
+import re
+from collections import OrderedDict, deque
 
 
 class CacheEntry:
-    def __init__(self, key, value, ttl_seconds=None):
+    __slots__ = ['key', 'original_key', 'value', 'created_at', 'last_accessed', 
+                 'access_count', 'ttl_seconds', 'size', 'expiration_time']
+    
+    def __init__(self, key, original_key, value, ttl_seconds=None):
         self.key = key
+        self.original_key = original_key
         self.value = value
         self.created_at = time.time()
-        self.last_accessed = time.time()
+        self.last_accessed = self.created_at
         self.access_count = 0
         self.ttl_seconds = ttl_seconds
         self.size = 0
+        if ttl_seconds is not None:
+            self.expiration_time = self.created_at + ttl_seconds
+        else:
+            self.expiration_time = None
 
 
-class UnoptimizedCache:
-    def __init__(self, max_size=1000, default_ttl=300):
-        self.entries = []
-        self.max_size = max_size
-        self.default_ttl = default_ttl
-        self.stats_log = ""
-        self.lock = threading.Lock()
-        self.hits = 0
-        self.misses = 0
+class OptimizedCache:
+    def __init__(self, max_size=1000, default_ttl=300, logging_enabled=True):
+        self._cache = OrderedDict()
+        self._max_size = max_size
+        self._default_ttl = default_ttl
+        self._lock = threading.RLock()
+        self._hits = 0
+        self._misses = 0
+        self._logging_enabled = logging_enabled
+        self._stats_log = deque(maxlen=10000)
+        self._ttl_heap = []
+        self._heap_counter = 0
     
-    def _compute_key_hash(self, key):
-        key_str = ""
+    def _normalize_key(self, key):
         if isinstance(key, dict):
-            for k in sorted(key.keys()):
-                key_str = key_str + str(k) + ":" + str(key[k]) + ","
+            return tuple(sorted((k, self._normalize_key(v)) for k, v in key.items()))
         elif isinstance(key, list):
-            for item in key:
-                key_str = key_str + str(item) + ","
+            return tuple(self._normalize_key(item) for item in key)
+        elif isinstance(key, (set, frozenset)):
+            return frozenset(self._normalize_key(item) for item in key)
         else:
-            key_str = str(key)
-        
-        hash_val = 0
-        for char in key_str:
-            hash_val = hash_val + ord(char)
-        return hash_val
+            return key
     
-    def _find_entry(self, key):
-        key_hash = self._compute_key_hash(key)
-        for entry in self.entries:
-            entry_hash = self._compute_key_hash(entry.key)
-            if entry_hash == key_hash:
-                if self._keys_equal(entry.key, key):
-                    return entry
-        return None
+    def _needs_copy(self, value):
+        return isinstance(value, (dict, list, set, bytearray))
     
-    def _keys_equal(self, key1, key2):
-        if type(key1) != type(key2):
-            return False
-        
-        if isinstance(key1, dict):
-            if len(key1) != len(key2):
-                return False
-            for k in key1:
-                if k not in key2:
-                    return False
-                if not self._keys_equal(key1[k], key2[k]):
-                    return False
-            return True
-        elif isinstance(key1, list):
-            if len(key1) != len(key2):
-                return False
-            for i in range(len(key1)):
-                if not self._keys_equal(key1[i], key2[i]):
-                    return False
-            return True
-        else:
-            return key1 == key2
+    def _safe_copy(self, value):
+        if self._needs_copy(value):
+            return copy.deepcopy(value)
+        return value
+    
+    def _calculate_entry_size(self, value):
+        if isinstance(value, (dict, list)):
+            return len(json.dumps(value))
+        return len(str(value))
     
     def _is_expired(self, entry):
-        if entry.ttl_seconds is None:
+        if entry.expiration_time is None:
             return False
-        current_time = time.time()
-        age = current_time - entry.created_at
-        if age > entry.ttl_seconds:
-            return True
-        return False
+        return time.time() > entry.expiration_time
     
-    def _calculate_entry_size(self, value):
-        size = 0
-        value_str = ""
-        if isinstance(value, dict):
-            value_str = json.dumps(value)
-        elif isinstance(value, list):
-            value_str = json.dumps(value)
-        else:
-            value_str = str(value)
-        
-        for char in value_str:
-            size = size + 1
-        return size
+    def _log(self, message):
+        if self._logging_enabled:
+            self._stats_log.append(message)
+    
+    def _cleanup_heap(self, max_items=100):
+        current_time = time.time()
+        cleaned = 0
+        while self._ttl_heap and cleaned < max_items:
+            exp_time, counter, norm_key = self._ttl_heap[0]
+            if exp_time > current_time:
+                break
+            heapq.heappop(self._ttl_heap)
+            if norm_key in self._cache:
+                entry = self._cache[norm_key]
+                if entry.expiration_time is not None and entry.expiration_time <= current_time:
+                    del self._cache[norm_key]
+                    cleaned += 1
+        return cleaned
     
     def get(self, key):
-        with self.lock:
-            entry = self._find_entry(key)
+        with self._lock:
+            norm_key = self._normalize_key(key)
+            entry = self._cache.get(norm_key)
             
             if entry is None:
-                self.misses = self.misses + 1
-                self.stats_log = self.stats_log + "MISS: " + str(key) + "\n"
+                self._misses += 1
+                self._log(f"MISS: {key}")
                 return None
             
             if self._is_expired(entry):
-                self._remove_entry(key)
-                self.misses = self.misses + 1
-                self.stats_log = self.stats_log + "EXPIRED: " + str(key) + "\n"
+                del self._cache[norm_key]
+                self._misses += 1
+                self._log(f"EXPIRED: {key}")
                 return None
             
+            self._cache.move_to_end(norm_key)
             entry.last_accessed = time.time()
-            entry.access_count = entry.access_count + 1
-            self.hits = self.hits + 1
-            self.stats_log = self.stats_log + "HIT: " + str(key) + "\n"
+            entry.access_count += 1
+            self._hits += 1
+            self._log(f"HIT: {key}")
             
-            return copy.deepcopy(entry.value)
+            return self._safe_copy(entry.value)
+    
+    def get_unsafe(self, key):
+        with self._lock:
+            norm_key = self._normalize_key(key)
+            entry = self._cache.get(norm_key)
+            
+            if entry is None:
+                self._misses += 1
+                return None
+            
+            if self._is_expired(entry):
+                del self._cache[norm_key]
+                self._misses += 1
+                return None
+            
+            self._cache.move_to_end(norm_key)
+            entry.last_accessed = time.time()
+            entry.access_count += 1
+            self._hits += 1
+            
+            return entry.value
     
     def set(self, key, value, ttl_seconds=None):
-        with self.lock:
+        with self._lock:
             if ttl_seconds is None:
-                ttl_seconds = self.default_ttl
+                ttl_seconds = self._default_ttl
+            
+            norm_key = self._normalize_key(key)
             
-            existing = self._find_entry(key)
-            if existing is not None:
-                self._remove_entry(key)
+            if norm_key in self._cache:
+                del self._cache[norm_key]
             
-            if len(self.entries) >= self.max_size:
-                self._evict_lru()
+            while len(self._cache) >= self._max_size:
+                evicted_key, evicted_entry = self._cache.popitem(last=False)
+                self._log(f"EVICTED: {evicted_entry.original_key}")
             
-            entry = CacheEntry(copy.deepcopy(key), copy.deepcopy(value), ttl_seconds)
+            stored_value = self._safe_copy(value) if self._needs_copy(value) else value
+            entry = CacheEntry(norm_key, key, stored_value, ttl_seconds)
             entry.size = self._calculate_entry_size(value)
-            self.entries.append(entry)
+            self._cache[norm_key] = entry
             
-            self.stats_log = self.stats_log + "SET: " + str(key) + "\n"
-    
-    def _remove_entry(self, key):
-        new_entries = []
-        for entry in self.entries:
-            if not self._keys_equal(entry.key, key):
-                new_entries.append(entry)
-        self.entries = new_entries
-    
-    def _evict_lru(self):
-        if len(self.entries) == 0:
-            return
-        
-        lru_entry = self.entries[0]
-        for entry in self.entries:
-            if entry.last_accessed < lru_entry.last_accessed:
-                lru_entry = entry
-        
-        self._remove_entry(lru_entry.key)
-        self.stats_log = self.stats_log + "EVICTED: " + str(lru_entry.key) + "\n"
+            if ttl_seconds is not None:
+                self._heap_counter += 1
+                heapq.heappush(self._ttl_heap, (entry.expiration_time, self._heap_counter, norm_key))
+            
+            self._log(f"SET: {key}")
     
     def delete(self, key):
-        with self.lock:
-            before_count = len(self.entries)
-            self._remove_entry(key)
-            after_count = len(self.entries)
-            
-            if before_count > after_count:
-                self.stats_log = self.stats_log + "DELETED: " + str(key) + "\n"
+        with self._lock:
+            norm_key = self._normalize_key(key)
+            if norm_key in self._cache:
+                del self._cache[norm_key]
+                self._log(f"DELETED: {key}")
                 return True
             return False
     
     def clear(self):
-        with self.lock:
-            self.entries = []
-            self.stats_log = self.stats_log + "CLEARED\n"
+        with self._lock:
+            self._cache.clear()
+            self._ttl_heap.clear()
+            self._heap_counter = 0
+            self._log("CLEARED")
     
     def cleanup_expired(self):
-        with self.lock:
+        with self._lock:
             expired_count = 0
-            new_entries = []
+            current_time = time.time()
             
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    new_entries.append(entry)
-                else:
-                    expired_count = expired_count + 1
+            while self._ttl_heap:
+                exp_time, counter, norm_key = self._ttl_heap[0]
+                if exp_time > current_time:
+                    break
+                heapq.heappop(self._ttl_heap)
+                if norm_key in self._cache:
+                    entry = self._cache[norm_key]
+                    if entry.expiration_time is not None and entry.expiration_time <= current_time:
+                        del self._cache[norm_key]
+                        expired_count += 1
             
-            self.entries = new_entries
-            self.stats_log = self.stats_log + "CLEANUP: removed " + str(expired_count) + " entries\n"
+            self._log(f"CLEANUP: removed {expired_count} entries")
             return expired_count
     
     def get_or_set(self, key, factory_func, ttl_seconds=None):
@@ -200,7 +204,6 @@ class UnoptimizedCache:
         results = {}
         for key in keys:
             value = self.get(key)
-            key_str = ""
             if isinstance(key, dict):
                 key_str = json.dumps(key, sort_keys=True)
             elif isinstance(key, list):
@@ -215,199 +218,161 @@ class UnoptimizedCache:
             self.set(key, value, ttl_seconds)
     
     def keys(self):
-        with self.lock:
+        with self._lock:
             result = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    result.append(copy.deepcopy(entry.key))
+            current_time = time.time()
+            for norm_key, entry in self._cache.items():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    result.append(self._safe_copy(entry.original_key))
             return result
     
     def values(self):
-        with self.lock:
+        with self._lock:
             result = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    result.append(copy.deepcopy(entry.value))
+            current_time = time.time()
+            for entry in self._cache.values():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    result.append(self._safe_copy(entry.value))
             return result
     
     def items(self):
-        with self.lock:
+        with self._lock:
             result = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    result.append((copy.deepcopy(entry.key), copy.deepcopy(entry.value)))
+            current_time = time.time()
+            for entry in self._cache.values():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    result.append((self._safe_copy(entry.original_key), self._safe_copy(entry.value)))
             return result
     
     def size(self):
-        with self.lock:
+        with self._lock:
+            current_time = time.time()
             count = 0
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    count = count + 1
+            for entry in self._cache.values():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    count += 1
             return count
     
     def total_memory_size(self):
-        with self.lock:
+        with self._lock:
             total = 0
-            for entry in self.entries:
-                total = total + entry.size
+            for entry in self._cache.values():
+                total += entry.size
             return total
     
     def get_stats(self):
-        with self.lock:
-            total = self.hits + self.misses
-            if total > 0:
-                hit_rate = self.hits / total
-            else:
-                hit_rate = 0
+        with self._lock:
+            total = self._hits + self._misses
+            hit_rate = self._hits / total if total > 0 else 0
             
             return {
-                "hits": self.hits,
-                "misses": self.misses,
+                "hits": self._hits,
+                "misses": self._misses,
                 "hit_rate": hit_rate,
                 "size": self.size(),
                 "total_memory": self.total_memory_size()
             }
     
     def find_by_prefix(self, prefix):
-        with self.lock:
+        with self._lock:
             results = []
             prefix_str = str(prefix)
+            current_time = time.time()
             
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    key_str = str(entry.key)
-                    
-                    matches = True
-                    if len(key_str) < len(prefix_str):
-                        matches = False
-                    else:
-                        for i in range(len(prefix_str)):
-                            if key_str[i] != prefix_str[i]:
-                                matches = False
-                                break
-                    
-                    if matches:
-                        results.append((copy.deepcopy(entry.key), copy.deepcopy(entry.value)))
+            for entry in self._cache.values():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    key_str = str(entry.original_key)
+                    if key_str.startswith(prefix_str):
+                        results.append((self._safe_copy(entry.original_key), self._safe_copy(entry.value)))
             
             return results
     
     def find_by_pattern(self, pattern):
-        with self.lock:
+        with self._lock:
             results = []
+            current_time = time.time()
             
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    key_str = str(entry.key)
-                    
-                    if self._matches_pattern(key_str, pattern):
-                        results.append((copy.deepcopy(entry.key), copy.deepcopy(entry.value)))
+            regex_pattern = ''
+            i = 0
+            while i < len(pattern):
+                c = pattern[i]
+                if c == '*':
+                    regex_pattern += '.*'
+                elif c == '?':
+                    regex_pattern += '.'
+                else:
+                    regex_pattern += re.escape(c)
+                i += 1
+            
+            compiled_pattern = re.compile('^' + regex_pattern + '$')
+            
+            for entry in self._cache.values():
+                if entry.expiration_time is None or entry.expiration_time > current_time:
+                    key_str = str(entry.original_key)
+                    if compiled_pattern.match(key_str):
+                        results.append((self._safe_copy(entry.original_key), self._safe_copy(entry.value)))
             
             return results
     
-    def _matches_pattern(self, text, pattern):
-        pattern_idx = 0
-        text_idx = 0
-        
-        while pattern_idx < len(pattern) and text_idx < len(text):
-            if pattern[pattern_idx] == '*':
-                if pattern_idx == len(pattern) - 1:
-                    return True
-                
-                next_char = pattern[pattern_idx + 1]
-                while text_idx < len(text) and text[text_idx] != next_char:
-                    text_idx = text_idx + 1
-                pattern_idx = pattern_idx + 1
-            elif pattern[pattern_idx] == '?':
-                pattern_idx = pattern_idx + 1
-                text_idx = text_idx + 1
-            elif pattern[pattern_idx] == text[text_idx]:
-                pattern_idx = pattern_idx + 1
-                text_idx = text_idx + 1
-            else:
-                return False
-        
-        while pattern_idx < len(pattern) and pattern[pattern_idx] == '*':
-            pattern_idx = pattern_idx + 1
-        
-        return pattern_idx == len(pattern) and text_idx == len(text)
-    
     def get_lru_entries(self, count):
-        with self.lock:
-            valid_entries = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    valid_entries.append(entry)
+        with self._lock:
+            current_time = time.time()
+            valid_entries = [
+                entry for entry in self._cache.values()
+                if entry.expiration_time is None or entry.expiration_time > current_time
+            ]
             
-            n = len(valid_entries)
-            for i in range(n):
-                for j in range(0, n - i - 1):
-                    if valid_entries[j].last_accessed > valid_entries[j + 1].last_accessed:
-                        temp = valid_entries[j]
-                        valid_entries[j] = valid_entries[j + 1]
-                        valid_entries[j + 1] = temp
+            lru_entries = heapq.nsmallest(count, valid_entries, key=lambda e: e.last_accessed)
             
-            results = []
-            for i in range(min(count, len(valid_entries))):
-                entry = valid_entries[i]
-                results.append({
-                    "key": copy.deepcopy(entry.key),
+            return [
+                {
+                    "key": self._safe_copy(entry.original_key),
                     "last_accessed": entry.last_accessed,
                     "access_count": entry.access_count
-                })
-            
-            return results
+                }
+                for entry in lru_entries
+            ]
     
     def get_mru_entries(self, count):
-        with self.lock:
-            valid_entries = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    valid_entries.append(entry)
+        with self._lock:
+            current_time = time.time()
+            valid_entries = [
+                entry for entry in self._cache.values()
+                if entry.expiration_time is None or entry.expiration_time > current_time
+            ]
             
-            n = len(valid_entries)
-            for i in range(n):
-                for j in range(0, n - i - 1):
-                    if valid_entries[j].last_accessed < valid_entries[j + 1].last_accessed:
-                        temp = valid_entries[j]
-                        valid_entries[j] = valid_entries[j + 1]
-                        valid_entries[j + 1] = temp
+            mru_entries = heapq.nlargest(count, valid_entries, key=lambda e: e.last_accessed)
             
-            results = []
-            for i in range(min(count, len(valid_entries))):
-                entry = valid_entries[i]
-                results.append({
-                    "key": copy.deepcopy(entry.key),
+            return [
+                {
+                    "key": self._safe_copy(entry.original_key),
                     "last_accessed": entry.last_accessed,
                     "access_count": entry.access_count
-                })
-            
-            return results
+                }
+                for entry in mru_entries
+            ]
     
     def get_most_accessed(self, count):
-        with self.lock:
-            valid_entries = []
-            for entry in self.entries:
-                if not self._is_expired(entry):
-                    valid_entries.append(entry)
+        with self._lock:
+            current_time = time.time()
+            valid_entries = [
+                entry for entry in self._cache.values()
+                if entry.expiration_time is None or entry.expiration_time > current_time
+            ]
             
-            n = len(valid_entries)
-            for i in range(n):
-                for j in range(0, n - i - 1):
-                    if valid_entries[j].access_count < valid_entries[j + 1].access_count:
-                        temp = valid_entries[j]
-                        valid_entries[j] = valid_entries[j + 1]
-                        valid_entries[j + 1] = temp
+            most_accessed = heapq.nlargest(count, valid_entries, key=lambda e: e.access_count)
             
-            results = []
-            for i in range(min(count, len(valid_entries))):
-                entry = valid_entries[i]
-                results.append({
-                    "key": copy.deepcopy(entry.key),
+            return [
+                {
+                    "key": self._safe_copy(entry.original_key),
                     "access_count": entry.access_count
-                })
-            
-            return results
+                }
+                for entry in most_accessed
+            ]
     
     def export_stats_log(self):
-        return self.stats_log
\ No newline at end of file
+        with self._lock:
+            return '\n'.join(self._stats_log) + ('\n' if self._stats_log else '')
+
+
+UnoptimizedCache = OptimizedCache
