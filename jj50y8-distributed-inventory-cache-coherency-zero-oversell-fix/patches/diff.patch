--- repository_before/src/inventory-service.ts	2026-01-24 00:59:03.521914826 +0300
+++ repository_after/src/inventory-service.ts	2026-01-24 01:10:56.802211894 +0300
@@ -1,111 +1,291 @@
 import { redis, db, logger, transaction } from './infrastructure';
+
+// Declare setTimeout for TypeScript
+declare function setTimeout(callback: () => void, ms: number): any;
+
+/**
+ * Helper function to delay execution
+ */
+function delay(ms: number): Promise<void> {
+  return new Promise<void>(resolve => {
+    setTimeout(() => {
+      resolve();
+    }, ms);
+  });
+}
+
 export class InventoryService {
   private readonly CACHE_TTL = 300; // 5 minutes
   private readonly CACHE_PREFIX = 'inventory:';
+  private readonly LOCK_PREFIX = 'lock:inventory:';
+  private readonly REPOP_LOCK_PREFIX = 'repop:inventory:';
+  private readonly LOCK_TTL = 10; // 10 seconds for operation locks
+  private readonly REPOP_LOCK_TTL = 5; // 5 seconds for repopulation locks
+
+  /**
+   * Acquire a distributed lock using Redis SET with NX and EX
+   * Returns true if lock was acquired, false otherwise
+   */
+  private async acquireLock(lockKey: string, ttl: number): Promise<boolean> {
+    try {
+      // ioredis SET with NX returns 'OK' if successful, null if key already exists
+      const result = await redis.set(lockKey, '1', 'EX', ttl, 'NX');
+      return result === 'OK';
+    } catch (error) {
+      logger.error({ error, lockKey, action: 'acquireLock' });
+      // On Redis failure, allow operation to proceed (fail-open for resilience)
+      // Database row-level locking will still prevent overselling
+      return false;
+    }
+  }
+
+  /**
+   * Release a distributed lock
+   */
+  private async releaseLock(lockKey: string): Promise<void> {
+    try {
+      await redis.del(lockKey);
+    } catch (error) {
+      logger.error({ error, lockKey, action: 'releaseLock' });
+    }
+  }
+
+  /**
+   * Repopulate cache from database with thundering herd protection
+   * Uses distributed lock to ensure only one server repopulates cache
+   */
+  private async repopulateCache(productId: string, cacheKey: string): Promise<number> {
+    const repopLockKey = `${this.REPOP_LOCK_PREFIX}${productId}`;
+    
+    // Try to acquire repopulation lock
+    const lockAcquired = await this.acquireLock(repopLockKey, this.REPOP_LOCK_TTL);
+    
+    if (lockAcquired) {
+      try {
+        // We acquired the lock, repopulate from database
+        const result = await db.query(
+          'SELECT stock_quantity FROM inventory WHERE product_id = $1',
+          [productId]
+        );
+        const stock = result.rows[0]?.stock_quantity ?? 0;
+        await redis.set(cacheKey, stock.toString(), 'EX', this.CACHE_TTL);
+        logger.info({ productId, source: 'database', stock, action: 'repopulate' });
+        return stock;
+      } finally {
+        await this.releaseLock(repopLockKey);
+      }
+    } else {
+      // Another server is repopulating, wait briefly and retry cache read
+      await delay(50);
+      const cached = await redis.get(cacheKey);
+      if (cached !== null) {
+        logger.info({ productId, source: 'cache', stock: cached, action: 'retry_after_repop_wait' });
+        return parseInt(cached, 10);
+      }
+      // If still not cached, fall back to database read (should be rare)
+      const result = await db.query(
+        'SELECT stock_quantity FROM inventory WHERE product_id = $1',
+        [productId]
+      );
+      const stock = result.rows[0]?.stock_quantity ?? 0;
+      logger.info({ productId, source: 'database', stock, action: 'fallback_after_repop_fail' });
+      return stock;
+    }
+  }
+
+  /**
+   * Get stock with cache-aside pattern and thundering herd protection
+   */
   async getStock(productId: string): Promise<number> {
     const cacheKey = `${this.CACHE_PREFIX}${productId}`;
+    
+    // Try cache first
     const cached = await redis.get(cacheKey);
     if (cached !== null) {
       logger.info({ productId, source: 'cache', stock: cached });
       return parseInt(cached, 10);
     }
-    const result = await db.query(
-      'SELECT stock_quantity FROM inventory WHERE product_id = $1',
-      [productId]
-    );
-
-    const stock = result.rows[0]?.stock_quantity ?? 0;
-    await redis.set(cacheKey, stock.toString(), 'EX', this.CACHE_TTL);
 
-    logger.info({ productId, source: 'database', stock });
-    return stock;
+    // Cache miss - repopulate with protection against thundering herd
+    return await this.repopulateCache(productId, cacheKey);
   }
 
   /**
+   * Decrement stock with zero-oversell guarantee
+   * Uses database transaction with row-level locking and cache invalidation
    * 
+   * The database FOR UPDATE lock ensures serialization and prevents overselling.
+   * The distributed lock helps serialize cache updates across servers.
    * 
-   * 
-   *
-   * 
-   * @throws {Error} 
+   * @throws {Error} If insufficient stock available
    */
   async decrementStock(productId: string, quantity: number): Promise<void> {
     const cacheKey = `${this.CACHE_PREFIX}${productId}`;
+    const lockKey = `${this.LOCK_PREFIX}${productId}`;
 
-    // Start database transaction
-    await transaction(async (client) => {
-      // Read current stock with row lock
-      const result = await client.query(
-        'SELECT stock_quantity FROM inventory WHERE product_id = $1 FOR UPDATE',
-        [productId]
-      );
-
-      const currentStock = result.rows[0]?.stock_quantity ?? 0;
-
-      // Validate sufficient stock
-      if (currentStock < quantity) {
-        throw new Error(`Insufficient stock: ${currentStock} available, ${quantity} requested`);
-      }
-
-      // Update database
-      const newStock = currentStock - quantity;
-      await client.query(
-        'UPDATE inventory SET stock_quantity = $1, updated_at = NOW() WHERE product_id = $2',
-        [newStock, productId]
-      );
-
-      // Audit log
-      await client.query(
-        'INSERT INTO inventory_audit (product_id, delta, new_quantity, timestamp) VALUES ($1, $2, $3, NOW())',
-        [productId, -quantity, newStock]
-      );
+    // Acquire distributed lock to serialize cache updates across servers
+    // This prevents race conditions in cache updates while database transaction provides
+    // the actual oversell protection via row-level locking
+    let lockAcquired = await this.acquireLock(lockKey, this.LOCK_TTL);
+    if (!lockAcquired) {
+      // Retry with exponential backoff (single retry for low latency)
+      await delay(10);
+      lockAcquired = await this.acquireLock(lockKey, this.LOCK_TTL);
+    }
 
-      logger.info({ 
-        productId, 
-        action: 'decrement', 
-        quantity, 
-        newStock 
+    try {
+      // Start database transaction - this is the source of truth
+      // FOR UPDATE ensures row-level locking and serialization
+      let newStock: number = 0;
+      await transaction(async (client) => {
+        // Read current stock with row lock (FOR UPDATE ensures serialization)
+        const result = await client.query(
+          'SELECT stock_quantity FROM inventory WHERE product_id = $1 FOR UPDATE',
+          [productId]
+        );
+
+        const currentStock = result.rows[0]?.stock_quantity ?? 0;
+
+        // Validate sufficient stock - this check is atomic within the transaction
+        if (currentStock < quantity) {
+          throw new Error(`Insufficient stock: ${currentStock} available, ${quantity} requested`);
+        }
+
+        // Update database atomically
+        newStock = currentStock - quantity;
+        await client.query(
+          'UPDATE inventory SET stock_quantity = $1, updated_at = NOW() WHERE product_id = $2',
+          [newStock, productId]
+        );
+
+        // Audit log (within same transaction for compliance requirement #6)
+        await client.query(
+          'INSERT INTO inventory_audit (product_id, delta, new_quantity, timestamp) VALUES ($1, $2, $3, NOW())',
+          [productId, -quantity, newStock]
+        );
+
+        logger.info({ 
+          productId, 
+          action: 'decrement', 
+          quantity, 
+          newStock 
+        });
       });
-    });
-
-    const updatedResult = await db.query(
-      'SELECT stock_quantity FROM inventory WHERE product_id = $1',
-      [productId]
-    );
-    const updatedStock = updatedResult.rows[0]?.stock_quantity ?? 0;
 
-    await redis.set(cacheKey, updatedStock.toString(), 'EX', this.CACHE_TTL);
+      // After transaction commit, update cache atomically
+      // We invalidate first, then set new value to ensure consistency
+      // If distributed lock was acquired, this prevents concurrent cache updates
+      // Only update cache if transaction succeeded (newStock is set)
+      if (newStock >= 0) {
+        try {
+          await redis.del(cacheKey);
+          // Pre-populate cache with new value to maintain high hit rate
+          // This happens immediately after commit, satisfying requirement #3 (100ms visibility)
+          await redis.set(cacheKey, newStock.toString(), 'EX', this.CACHE_TTL);
+        } catch (cacheError) {
+          // If cache update fails, log but don't fail the operation
+          // Database is source of truth, cache will be repopulated on next read
+          logger.error({ 
+            error: cacheError, 
+            productId, 
+            action: 'cache_update_failed',
+            note: 'Database transaction committed successfully, cache will be repopulated on next read'
+          });
+        }
+      }
+      
+    } catch (error) {
+      // On error, invalidate cache to ensure consistency
+      // This prevents serving stale cached values after a failed transaction
+      try {
+        await redis.del(cacheKey);
+      } catch (cacheError) {
+        logger.error({ error: cacheError, productId, action: 'cache_invalidation_on_error' });
+      }
+      throw error;
+    } finally {
+      // Always release the distributed lock if we acquired it
+      if (lockAcquired) {
+        await this.releaseLock(lockKey);
+      }
+    }
   }
+
+  /**
+   * Increment stock with cache coherency
+   * Uses same pattern as decrementStock for consistency
+   */
   async incrementStock(productId: string, quantity: number): Promise<void> {
     const cacheKey = `${this.CACHE_PREFIX}${productId}`;
+    const lockKey = `${this.LOCK_PREFIX}${productId}`;
 
-    await transaction(async (client) => {
-      const result = await client.query(
-        'SELECT stock_quantity FROM inventory WHERE product_id = $1 FOR UPDATE',
-        [productId]
-      );
-
-      const currentStock = result.rows[0]?.stock_quantity ?? 0;
-      const newStock = currentStock + quantity;
-
-      await client.query(
-        'UPDATE inventory SET stock_quantity = $1, updated_at = NOW() WHERE product_id = $2',
-        [newStock, productId]
-      );
-
-      await client.query(
-        'INSERT INTO inventory_audit (product_id, delta, new_quantity, timestamp) VALUES ($1, $2, $3, NOW())',
-        [productId, quantity, newStock]
-      );
+    // Acquire distributed lock to serialize cache updates across servers
+    let lockAcquired = await this.acquireLock(lockKey, this.LOCK_TTL);
+    if (!lockAcquired) {
+      await delay(10);
+      lockAcquired = await this.acquireLock(lockKey, this.LOCK_TTL);
+    }
 
-      logger.info({ 
-        productId, 
-        action: 'increment', 
-        quantity, 
-        newStock 
+    try {
+      let newStock: number = 0;
+      await transaction(async (client) => {
+        const result = await client.query(
+          'SELECT stock_quantity FROM inventory WHERE product_id = $1 FOR UPDATE',
+          [productId]
+        );
+
+        const currentStock = result.rows[0]?.stock_quantity ?? 0;
+        newStock = currentStock + quantity;
+
+        await client.query(
+          'UPDATE inventory SET stock_quantity = $1, updated_at = NOW() WHERE product_id = $2',
+          [newStock, productId]
+        );
+
+        // Audit log (within same transaction for compliance requirement #6)
+        await client.query(
+          'INSERT INTO inventory_audit (product_id, delta, new_quantity, timestamp) VALUES ($1, $2, $3, NOW())',
+          [productId, quantity, newStock]
+        );
+
+        logger.info({ 
+          productId, 
+          action: 'increment', 
+          quantity, 
+          newStock 
+        });
       });
-    });
 
-    await redis.del(cacheKey);
+      // Update cache immediately after transaction commit
+      // Same pattern as decrementStock for consistency
+      // Only update cache if transaction succeeded (newStock is set)
+      if (newStock >= 0) {
+        try {
+          await redis.del(cacheKey);
+          await redis.set(cacheKey, newStock.toString(), 'EX', this.CACHE_TTL);
+        } catch (cacheError) {
+          logger.error({ 
+            error: cacheError, 
+            productId, 
+            action: 'cache_update_failed',
+            note: 'Database transaction committed successfully, cache will be repopulated on next read'
+          });
+        }
+      }
+      
+    } catch (error) {
+      // On error, invalidate cache to ensure consistency
+      try {
+        await redis.del(cacheKey);
+      } catch (cacheError) {
+        logger.error({ error: cacheError, productId, action: 'cache_invalidation_on_error' });
+      }
+      throw error;
+    } finally {
+      // Always release the distributed lock if we acquired it
+      if (lockAcquired) {
+        await this.releaseLock(lockKey);
+      }
+    }
   }
 }
